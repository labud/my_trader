import numpy as np
import pandas as pd
from pandas import DataFrame
import os
import json
import multiprocessing
from datetime import datetime
from sklearn.model_selection import ParameterGrid
from joblib import Parallel, delayed
from ds_fee.BacktestEngine import BacktestEngine

class OptimizationConfig:
    def __init__(
        self,
        min_annual_return=0.03,   # æœ€ä½å¹´åŒ–æ”¶ç›Š3%
        max_drawdown=0.30,        # å…è®¸æœ€å¤§å›æ’¤30%
        min_sharpe=0.8,           # å¤æ™®æ¯”ç‡â‰¥0.8
        min_win_rate=0.30,        # èƒœç‡â‰¥30%
        max_position_days=15,     # æœ€å¤§æŒä»“15å¤©
        max_volatility=0.40       # æ³¢åŠ¨ç‡â‰¤40%
    ):
        # é£é™©æ”¶ç›ŠæŒ‡æ ‡é˜ˆå€¼
        self.min_annual_return = min_annual_return  # æœ€å°å¹´åŒ–æ”¶ç›Šç‡
        self.max_drawdown = max_drawdown            # æœ€å¤§å›æ’¤
        self.min_sharpe = min_sharpe                # æœ€å°å¤æ™®æ¯”ç‡
        self.min_win_rate = min_win_rate            # æœ€å°èƒœç‡
        self.max_position_days = max_position_days  # æœ€å¤§æŒä»“å¤©æ•°
        self.max_volatility = max_volatility        # æœ€å¤§æ³¢åŠ¨ç‡

    @classmethod
    def from_dict(cls, config_dict):
        """ä»å­—å…¸åˆ›å»ºé…ç½®å¯¹è±¡"""
        return cls(**config_dict)

class OptimizationDashboard:
    def print_best_result(self, results):
        # è¿‡æ»¤æ— æ•ˆç»“æœ
        valid_results = [r for r in results if r.get('metrics')]
        
        if valid_results:
            # å§‹ç»ˆæ˜¾ç¤ºå…¨å±€æœ€ä¼˜å¤æ™®ç»„åˆ
            best_sharpe = max(valid_results, 
                            key=lambda x: x['metrics'].get('sharpe_ratio', -np.inf))
            print("\nğŸ“ˆ å½“å‰æœ€ä¼˜å¤æ™®ç»„åˆ:")
            for k, v in best_sharpe['params'].items():
                print(f"  â–¸ {k}: {v}")
            print(f"  å¤æ™®æ¯”ç‡: {best_sharpe['metrics']['sharpe_ratio']:.2f}")
            print(f"  å¹´åŒ–æ”¶ç›Š: {best_sharpe['metrics']['annualized_return']:.2%}")
            print(f"  æœ€å¤§å›æ’¤: {best_sharpe['metrics']['max_drawdown']:.2%}")
            print(f"  æ˜¯å¦åˆæ ¼: {'âœ…' if best_sharpe['qualified'] else 'âŒ'}")

            # æ˜¾ç¤ºå…¨å±€æ”¶ç›Šæœ€é«˜çš„ç»„åˆï¼ˆå³ä½¿ä¸åˆæ ¼ï¼‰
            best_profit = max(valid_results, 
                            key=lambda x: x['metrics'].get('annualized_return', -np.inf))
            print("\nğŸ† å…¨å±€æœ€é«˜æ”¶ç›Šç»„åˆ:")
            for k, v in best_profit['params'].items():
                print(f"  â–¸ {k}: {v}")
            print(f"  å¹´åŒ–æ”¶ç›Š: {best_profit['metrics']['annualized_return']:.2%}")
            print(f"  å¤æ™®æ¯”ç‡: {best_profit['metrics'].get('sharpe_ratio', 0):.2f}")
            print(f"  æœ€å¤§å›æ’¤: {best_profit['metrics']['max_drawdown']:.2%}")
            print(f"  æ˜¯å¦åˆæ ¼: {'âœ…' if best_profit['qualified'] else 'âŒ'}")

def serialize_preprocessed_data(df: DataFrame) -> dict:
    """åºåˆ—åŒ–é¢„å¤„ç†æ•°æ®ä¸ºå¯ä¼ è¾“æ ¼å¼"""
    return {
        'features': df.values.tolist(),  # ç»Ÿä¸€ä½¿ç”¨featuresä½œä¸ºæ•°æ®é”®
        'index': df.index.tolist(),
        'columns': df.columns.tolist()
    }

def deserialize_preprocessed_data(data_dict: dict) -> DataFrame:
    """ååºåˆ—åŒ–é¢„å¤„ç†æ•°æ®ä¸ºDataFrame"""
    return DataFrame(
        data=data_dict['features'],  # åŒæ­¥ä¿®æ”¹ä¸ºfeatures
        index=pd.to_datetime(data_dict['index']),
        columns=data_dict['columns']
    )

def is_qualified(metrics, optimization_config):
    """æ£€æŸ¥å‚æ•°ç»„åˆæ˜¯å¦æ»¡è¶³é£æ§è¦æ±‚ï¼ˆå…¨å±€å‡½æ•°ç‰ˆæœ¬ï¼‰"""
    return (
        metrics['annualized_return'] >= optimization_config.min_annual_return and
        metrics['max_drawdown'] <= optimization_config.max_drawdown and
        metrics['sharpe_ratio'] >= optimization_config.min_sharpe and
        metrics['win_rate'] >= optimization_config.min_win_rate
    )

def evaluate_params(params, serializable_data, optimization_config, verbose=False):
    """æ‰§è¡Œå•ä¸ªå‚æ•°ç»„åˆçš„å›æµ‹è¯„ä¼°ï¼ˆå…¨å±€å‡½æ•°ç‰ˆæœ¬ï¼‰"""
    if verbose:
        print(f"\nğŸ” å¼€å§‹å›æµ‹å‚æ•°ç»„åˆ:", flush=True)
        for k,v in params.items():
            print(f"  {k}: {v}", flush=True)
    
    # ç›´æ¥ä»åºåˆ—åŒ–æ•°æ®è·å–é¢„å¤„ç†ç»“æœ
    try:
        # åˆå¹¶åŸºç¡€é…ç½®å‚æ•°ï¼ˆåŒ…å«fee_rateï¼‰
        full_config = {
            **serializable_data['base_config'],  # åŸºç¡€é…ç½®å‚æ•°
            **params,                            # ä¼˜åŒ–å‚æ•°
            'output_dir': 'output'
        }
        
        # ä½¿ç”¨é¢„å¤„ç†çš„é…ç½®å’Œæ•°æ®ç›´æ¥åˆå§‹åŒ–å¼•æ“
        engine = BacktestEngine(config=full_config)
        engine.preprocessed_data = deserialize_preprocessed_data(serializable_data['preprocessed_data'])
        
    except KeyError as e:
        raise ValueError(f"Invalid serialized data format: {str(e)}") from e
    
    results = engine.run_backtest(full_config, verbose=verbose, saveResults=False)
    
    metrics = results.get('risk_metrics', {})
    return {
        'params': params.copy(),
        'metrics': {
            'annualized_return': metrics.get('annualized_return', -np.inf),
            'max_drawdown': metrics.get('max_drawdown', 1.0),
            'sharpe_ratio': metrics.get('sharpe_ratio', -np.inf),
            'profit_factor': metrics.get('profit_factor', 0),
            'win_rate': metrics.get('win_rate', 0),
            'volatility': metrics.get('annualized_volatility', np.inf)
        },
        'qualified': is_qualified(metrics, optimization_config) if metrics else False,
        'error': None
    }

def process_result(result, shared_completed, shared_best_score, shared_lock, total_combinations):
    """å¤„ç†å•ä¸ªç»“æœï¼ˆå…¨å±€å‡½æ•°ç‰ˆæœ¬ï¼‰"""
    with shared_lock:
        shared_completed.value += 1
        elapsed = pd.Timestamp.now().strftime('%H:%M:%S')
        print(f"[{elapsed}] å·²å®Œæˆ {shared_completed.value}/{total_combinations} ({shared_completed.value/total_combinations:.1%})")
        
        if result and result.get('error'):
            print(f"âš ï¸ å‚æ•°ç»„åˆ {result['params']} æ‰§è¡Œå¤±è´¥: {result['error']}")
            return result
            
        if result and result.get('metrics'):
            current_score = result['metrics']['sharpe_ratio']
            if current_score > shared_best_score.value:
                shared_best_score.value = current_score
                print(f"\nğŸŒŸ å‘ç°æ–°çš„æœ€ä½³ç»„åˆï¼ˆå¤æ™®æ¯”ç‡:{current_score:.2f}ï¼‰:")
                for k, v in result['params'].items():
                    print(f"   â”œ {k}: {v}")
                print(f"   â”œ å¹´åŒ–æ”¶ç›Š: {result['metrics']['annualized_return']:.2%}")
                print(f"   â”” æœ€å¤§å›æ’¤: {result['metrics']['max_drawdown']:.2%}")
        return result

# åˆ›å»ºå…¨å±€ä»»åŠ¡åŒ…è£…å‡½æ•°
def task_wrapper(params, serializable_data, optimization_config, verbose,
                shared_completed, shared_best_score, shared_lock, total_combinations):
    """å¹¶è¡Œä»»åŠ¡åŒ…è£…å‡½æ•°"""
    try:
        result = evaluate_params(
            params=params,
            serializable_data=serializable_data,
            optimization_config=optimization_config,
            verbose=verbose
        )
    except Exception as e:
        return {'params': params, 'error': str(e)}
    return process_result(
        result=result,
        shared_completed=shared_completed,
        shared_best_score=shared_best_score,
        shared_lock=shared_lock,
        total_combinations=total_combinations
    )
        
class ParameterOptimizer:
    def __init__(self, base_config, param_space, optimization_config=None):
        # è½¬æ¢é…ç½®å¯¹è±¡ä¸ºå­—å…¸æ ¼å¼
        self.base_config = base_config
        self.param_space = param_space
        self.optimization_config = optimization_config or OptimizationConfig()
        self.dashboard = OptimizationDashboard()
        self.manager = multiprocessing.Manager()
        self.shared_completed = self.manager.Value('i', 0)
        self.shared_best_score = self.manager.Value('d', -np.inf)
        self.shared_lock = self.manager.Lock()

    def grid_search(self, data, n_jobs=-1, verbose=False):
        """å¹¶è¡ŒåŒ–ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        grid = list(ParameterGrid(self.param_space))
        total_combinations = len(grid)
        
        print(f"\nğŸ”§ æ­£åœ¨åˆå§‹åŒ–{total_combinations}ä¸ªå‚æ•°ç»„åˆ...", flush=True)
        print(f"âš™ï¸ å¯åŠ¨{n_jobs if n_jobs != -1 else 'å…¨éƒ¨'}ä¸ªå¹¶è¡Œå·¥ä½œè¿›ç¨‹", flush=True)
        print(f"ğŸ•’ å¼€å§‹æ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}", flush=True)

        # å°†é¢„å¤„ç†æ•°æ®å’ŒåŸºç¡€é…ç½®åºåˆ—åŒ–
        serializable_data = {
            'base_config': self.base_config,  # åŒ…å«æ‰€æœ‰åŸºç¡€é…ç½®å‚æ•°
            'preprocessed_data': serialize_preprocessed_data(data)
        }
        
        # æ‰§è¡Œå¹¶è¡Œä»»åŠ¡å¹¶å®æ—¶å¤„ç†ç»“æœ
        with Parallel(n_jobs=n_jobs, verbose=5, timeout=3600) as parallel:
            results = []
            for result in parallel(delayed(task_wrapper)(
                params, 
                serializable_data,
                self.optimization_config,
                verbose,
                self.shared_completed,
                self.shared_best_score,
                self.shared_lock,
                total_combinations
            ) for params in grid):
                results.append(result)
        
        # è¿‡æ»¤åˆæ ¼ç»“æœ
        qualified_results = [res for res in results if res.get('qualified')]
        self._save_results(qualified_results)
        
        # æœ€ç»ˆç»“æœå±•ç¤º
        self.dashboard.print_best_result(results)
        
        return sorted(qualified_results, key=lambda x: x['metrics']['sharpe_ratio'], reverse=True)

    def _save_results(self, results):
        """ä¿å­˜ä¼˜åŒ–ç»“æœå’Œå†å²è®°å½•"""
        history_dir = "output/optimization_history"
        os.makedirs(history_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{history_dir}/optimized_params_{timestamp}.csv"
        
        # æ„å»ºåŒ…å«å®Œæ•´æŒ‡æ ‡çš„ç»“æœDataFrame
        df = pd.DataFrame([{
            **res['params'],
            'annualized_return': res['metrics']['annualized_return'],
            'max_drawdown': res['metrics']['max_drawdown'],
            'sharpe_ratio': res['metrics']['sharpe_ratio'],
            'win_rate': res['metrics']['win_rate'],
            'volatility': res['metrics']['volatility'],
            'profit_factor': res['metrics']['profit_factor'],
            'avg_holding_days': res['metrics']['avg_holding_days'],
            'total_trades': res['metrics']['total_trades'],
            'qualified': res['qualified']
        } for res in results if res['metrics']])
        
        # ä¿å­˜æœ¬æ¬¡ç»“æœ
        df.to_csv(filename, index=False)
        
        # æ›´æ–°ä¼˜åŒ–æ—¥å¿—
        log_entry = {
            'timestamp': timestamp,
            'total_combinations': len(results),
            'qualified_count': len([r for r in results if r['qualified']]),
            'best_sharpe': df['sharpe_ratio'].max() if not df.empty else None
        }
        log_path = f"{history_dir}/optimization_log.csv"
        pd.DataFrame([log_entry]).to_csv(log_path, mode='a', header=not os.path.exists(log_path))

    def _evaluate_params(self, params, data):
        """è¯„ä¼°å•ä¸ªå‚æ•°ç»„åˆï¼ˆç±»æ–¹æ³•ç‰ˆæœ¬ï¼‰"""
        return evaluate_params(
            params=params,
            serializable_data={
                'base_config': self.base_config,
                'preprocessed_data': serialize_preprocessed_data(data)
            },
            optimization_config=self.optimization_config,
            verbose=False
        )

    def genetic_optimization(self, data, population_size=50, generations=20, verbose=False):
        """é—ä¼ ç®—æ³•ä¼˜åŒ–å™¨"""
        # åˆå§‹åŒ–ç§ç¾¤
        population = self._initialize_population(population_size)
        
        for gen in range(generations):
            # è¯„ä¼°é€‚åº”åº¦
            # è¿‡æ»¤æ— æ•ˆè¯„ä¼°ç»“æœ
            evaluated_pop = [res for res in 
                           (self._evaluate_params(ind, data) for ind in population)
                           if res and res['metrics'] is not None]
            
            # é€‰æ‹©
            selected = self._selection(evaluated_pop)
            
            # äº¤å‰
            offspring = self._crossover(selected)
            
            # å˜å¼‚
            population = self._mutation(offspring)
            
            # æ˜¾ç¤ºè¿›åº¦
            self.dashboard.print_best_result(evaluated_pop)
        
        return sorted(evaluated_pop, key=lambda x: x['metrics']['sharpe_ratio'], reverse=True)

    def _initialize_population(self, size):
        """ç”Ÿæˆåˆå§‹ç§ç¾¤"""
        population = []
        for _ in range(size):
            individual = {
                'spread_threshold': np.round(np.random.uniform(0.002, 0.006), 4),  # ä»·å·®èŒƒå›´0.2%-0.6%
                'leverage': np.random.choice([2, 3, 4]),                          # æ æ†å€æ•°é€‰é¡¹
                'max_hold_seconds': np.random.choice([3600, 7200, 14400]),         # æŒä»“æ—¶é—´1-4å°æ—¶
                'take_profit': np.random.choice(np.arange(0.004, 0.012, 0.001)),  # æ­¢ç›ˆèŒƒå›´0.4%-1.2% æ­¥é•¿0.1%
                'stop_loss': np.random.choice(np.arange(0.003, 0.008, 0.001))    # æ­¢æŸèŒƒå›´0.3%-0.8% æ­¥é•¿0.1%
            }
            population.append(individual)
        return population

    def _selection(self, population):
        """é”¦æ ‡èµ›é€‰æ‹©"""
        selected = []
        tournament_size = 5
        for _ in range(len(population)):
            candidates = np.random.choice(population, tournament_size, replace=False)
            winner = max(
                [c for c in candidates if c['metrics'] is not None], 
                key=lambda x: x['metrics'].get('sharpe_ratio', -np.inf)
            )
            selected.append(winner['params'])
        return selected

    def _crossover(self, parents):
        """å‡åŒ€äº¤å‰"""
        offspring = []
        for i in range(0, len(parents), 2):
            p1 = parents[i]
            p2 = parents[i+1] if i+1 < len(parents) else parents[0]
            child = {}
            for key in p1:
                if np.random.rand() < 0.5:
                    child[key] = p1[key]
                else:
                    child[key] = p2[key]
            offspring.append(child)
        return offspring

    def random_sampling(self, raw_data, samples=500):
        """éšæœºé‡‡æ ·ä¼˜åŒ–"""
        print(f"\nğŸ² å¼€å§‹éšæœºé‡‡æ ·ï¼Œæ ·æœ¬æ•°: {samples}")
        
        # ç»Ÿä¸€æ•°æ®åºåˆ—åŒ–æ ¼å¼
        data = {
            'base_config': self.base_config,
            'preprocessed_data': serialize_preprocessed_data(raw_data)
        }
        
        results = []
        for i in range(samples):
            # ç”Ÿæˆéšæœºå‚æ•°
            params = {
                'spread_threshold': np.round(np.random.uniform(0.002, 0.006), 4),
                'leverage': np.random.choice([2, 3, 4]),
                'max_hold_seconds': np.random.choice([3600, 7200, 14400]),
                'take_profit': np.random.choice(np.arange(0.004, 0.012, 0.001)),  # ä»æ­¥é•¿0.1%çš„ç¦»æ•£å€¼ä¸­é€‰æ‹©
                'stop_loss': np.random.choice(np.arange(0.003, 0.008, 0.001))     # ä»æ­¥é•¿0.1%çš„ç¦»æ•£å€¼ä¸­é€‰æ‹©
            }
            # è¯„ä¼°å‚æ•°
            result = self._evaluate_params(params, data)
            results.append(result)
            # æ›´æ–°è¿›åº¦
            if (i+1) % 10 == 0 or (i+1) == samples:
                print(f"è¿›åº¦: {i+1}/{samples} ({(i+1)/samples:.1%})")
                self.dashboard.print_best_result(results)
        # è¿‡æ»¤æ— æ•ˆç»“æœå¹¶æ’åº
        valid_results = [r for r in results if r['metrics'] is not None]
        return sorted(valid_results, key=lambda x: x['metrics'].get('sharpe_ratio', -np.inf), reverse=True)

    def _mutation(self, offspring):
        """é«˜æ–¯å˜å¼‚ï¼ˆæ›´æ–°å‚æ•°èŒƒå›´ï¼‰"""
        mutated = []
        for params in offspring:
            mutated_params = params.copy()
            # ä»·å·®é˜ˆå€¼å˜å¼‚ (æ–°èŒƒå›´0.002-0.006)
            if np.random.rand() < 0.1:
                mutated_params['spread_threshold'] = np.clip(
                    np.random.normal(params['spread_threshold'], 0.001),
                    0.002, 0.006
                ).round(4)
            # æ æ†å€æ•°å˜å¼‚ (æ–°èŒƒå›´2-4)
            if np.random.rand() < 0.1:
                mutated_params['leverage'] = np.random.choice([2, 3, 4])
            # æŒä»“æ—¶é—´å˜å¼‚ (æ–°é€‰é¡¹)
            if np.random.rand() < 0.1:
                mutated_params['max_hold_seconds'] = np.random.choice([3600, 7200, 14400])
            # æ­¢ç›ˆå‚æ•°å˜å¼‚ (ä»é¢„å®šä¹‰æ­¥é•¿ä¸­é€‰æ‹©)
            if np.random.rand() < 0.1:
                mutated_params['take_profit'] = np.random.choice(np.arange(0.004, 0.012, 0.001))
            # æ­¢æŸå‚æ•°å˜å¼‚ (ä»é¢„å®šä¹‰æ­¥é•¿ä¸­é€‰æ‹©)
            if np.random.rand() < 0.1:
                mutated_params['stop_loss'] = np.random.choice(np.arange(0.003, 0.008, 0.001))
            mutated.append(mutated_params)
        return mutated

    def _sharpe_scorer(self, estimator, X, y):
        """è‡ªå®šä¹‰å¤æ™®æ¯”ç‡è¯„åˆ†å‡½æ•°"""
        estimator.run_backtest()
        metrics = estimator.analyze_performance()
        return metrics['sharpe_ratio']

    def save_full_report(self, results, output_dir):
        """ä¿å­˜å®Œæ•´ä¼˜åŒ–æŠ¥å‘Š"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜CSVç»“æœ
        df = pd.DataFrame([{
            **res['params'],
            **res['metrics'],
            'qualified': res['qualified']
        } for res in results])
        csv_path = f"{output_dir}/optimization_report_{timestamp}.csv"
        df.to_csv(csv_path, index=False)
        
        # ä¿å­˜å…ƒæ•°æ®
        # åªå¤„ç†åˆæ ¼ç»“æœ
        qualified = [res for res in results if res['qualified']]
        meta = {
            "optimization_date": timestamp,
            "total_combinations": len(results),
            "qualified_count": len(qualified),
            "best_sharpe": max((res['metrics']['sharpe_ratio'] for res in qualified), default=None)
        } if qualified else {
            "optimization_date": timestamp,
            "total_combinations": len(results),
            "qualified_count": 0,
            "best_sharpe": None
        }
        json_path = f"{output_dir}/metadata_{timestamp}.json"
        with open(json_path, 'w') as f:
            json.dump(meta, f, indent=2)

if __name__ == "__main__":
    import argparse
    import json
    from ds_fee.config import load_base_config
    
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='é‡åŒ–ç­–ç•¥å‚æ•°ä¼˜åŒ–æ‰§è¡Œå™¨', 
                                   formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--method', choices=['grid','genetic','random'], default='genetic',
                      help='é€‰æ‹©ä¼˜åŒ–ç®—æ³•: grid-ç½‘æ ¼æœç´¢, genetic-é—ä¼ ç®—æ³•, random-éšæœºé‡‡æ ·')
    parser.add_argument('--output', type=str, default='optimization_results',
                      help='ç»“æœè¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--jobs', type=int, default=-1,
                      help='å¹¶è¡Œä»»åŠ¡æ•°ï¼ˆ-1è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨CPUæ ¸å¿ƒï¼‰')
    parser.add_argument('--verbose', action='store_true',
                      help='å¯ç”¨è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    args = parser.parse_args()

    # åˆå§‹åŒ–ä¼˜åŒ–å™¨é…ç½®
    base_config = load_base_config()
    param_ranges = {
        'spread_threshold': np.arange(0.002, 0.006, 0.0005),  # è°ƒæ•´åˆ°æ›´åˆç†çš„ä»·å·®èŒƒå›´
        'leverage': [2, 3, 4],
        'max_hold_seconds': [3600, 7200, 14400],  # 1-4å°æ—¶æ›´åˆç†çš„æŒä»“æ—¶é—´
        'take_profit': np.arange(0.004, 0.012, 0.001),  # æ–°å¢æ­¢ç›ˆå‚æ•°
        'stop_loss': np.arange(0.003, 0.008, 0.001)     # æ–°å¢æ­¢æŸå‚æ•°
    }
    optimizer = ParameterOptimizer(base_config, param_ranges)  # ä¿®æ­£å˜é‡åé”™è¯¯

    try:
        # ä½¿ç”¨å·²åŠ è½½çš„åŸºç¡€é…ç½®åˆå§‹åŒ–å¼•æ“
        engine = BacktestEngine(base_config)
        engine.preprocess_data()
        data = engine.preprocessed_data
        
        print(f"âœ… æˆåŠŸåŠ è½½é¢„å¤„ç†æ•°æ®ï¼ˆ{len(data):,} æ¡è®°å½•ï¼‰")

        # æ‰§è¡Œä¼˜åŒ–
        print(f"ğŸš€ å¼€å§‹å‚æ•°ä¼˜åŒ–ï¼ˆæ–¹æ³•: {args.method.upper()}ï¼‰")
        if args.method == 'grid':
            results = optimizer.grid_search(data, n_jobs=args.jobs, verbose=args.verbose)
        elif args.method == 'genetic':
            results = optimizer.genetic_optimization(data, verbose=args.verbose)
        elif args.method == 'random':
            results = optimizer.random_sampling(data, verbose=args.verbose)
        
        # ä¿å­˜ç»“æœ
        # è¿‡æ»¤æ— æ•ˆç»“æœå¹¶ä¿å­˜
        valid_results = [r for r in results if r['metrics'] is not None]
        optimizer.save_full_report(valid_results, args.output)
        print(f"\nğŸ‰ ä¼˜åŒ–å®Œæˆï¼æœ‰æ•ˆå‚æ•°ç»„åˆ: {len(valid_results)} ä¸ª")
        print(f"ğŸ“‚ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {os.path.abspath(args.output)}")
        
        # å¤„ç†ä¼˜åŒ–ç»“æœ
        if valid_results:
            qualified = [res for res in results if res['qualified']]
            print(f"\nğŸ‰ ä¼˜åŒ–å®Œæˆï¼æ€»å‚æ•°ç»„åˆ: {len(results)} åˆæ ¼å‚æ•°: {len(qualified)}")
            
            if qualified:
                best_result = max(qualified, key=lambda x: x['metrics']['sharpe_ratio'])
                print("\nğŸ† æœ€ä½³å‚æ•°ç»„åˆ:")
                for k, v in best_result['params'].items():
                    print(f"  â–¸ {k:.<20} {v}")
                print(f"â­ å¤æ™®æ¯”ç‡: {best_result['metrics']['sharpe_ratio']:.2f}")
            else:
                print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆé£æ§è¦æ±‚çš„å‚æ•°ç»„åˆï¼Œå»ºè®®ï¼š")
                print("1. æ£€æŸ¥ç­–ç•¥é€»è¾‘æ˜¯å¦æ­£ç¡®")
                print("2. è°ƒæ•´ä¼˜åŒ–å‚æ•°èŒƒå›´")
                print("3. æ”¾å®½é£æ§æŒ‡æ ‡é˜ˆå€¼")
        else:
            print("\nâŒ ä¼˜åŒ–å¤±è´¥ï¼šæœªå¾—åˆ°ä»»ä½•æœ‰æ•ˆç»“æœ")

    except FileNotFoundError as e:
        print(f"âŒ å¸‚åœºæ•°æ®ç›®å½•ä¸å­˜åœ¨: {e.filename}")
        print("è¯·æ£€æŸ¥ds_fee/market_dataç›®å½•ç»“æ„æ˜¯å¦ç¬¦åˆè¦æ±‚")
    except pd.errors.EmptyDataError:
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯: {args.data}")
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤±è´¥: {str(e)}")
        raise
