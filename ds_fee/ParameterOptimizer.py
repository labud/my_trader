import numpy as np
import pandas as pd
import os
import json
from datetime import datetime
from sklearn.model_selection import ParameterGrid
from joblib import Parallel, delayed
from ds_fee.BacktestEngine import BacktestEngine

class OptimizationConfig:
    def __init__(
        self,
        min_annual_return=0.03,   # æœ€ä½å¹´åŒ–æ”¶ç›Š3%
        max_drawdown=0.30,        # å…è®¸æœ€å¤§å›æ’¤30%
        min_sharpe=0.8,           # å¤æ™®æ¯”ç‡â‰¥0.8
        min_win_rate=0.30,        # èƒœç‡â‰¥30%
        max_position_days=15,     # æœ€å¤§æŒä»“15å¤©
        max_volatility=0.40       # æ³¢åŠ¨ç‡â‰¤40%
    ):
        # é£é™©æ”¶ç›ŠæŒ‡æ ‡é˜ˆå€¼
        self.min_annual_return = min_annual_return  # æœ€å°å¹´åŒ–æ”¶ç›Šç‡
        self.max_drawdown = max_drawdown            # æœ€å¤§å›æ’¤
        self.min_sharpe = min_sharpe                # æœ€å°å¤æ™®æ¯”ç‡
        self.min_win_rate = min_win_rate            # æœ€å°èƒœç‡
        self.max_position_days = max_position_days  # æœ€å¤§æŒä»“å¤©æ•°
        self.max_volatility = max_volatility        # æœ€å¤§æ³¢åŠ¨ç‡

    @classmethod
    def from_dict(cls, config_dict):
        """ä»å­—å…¸åˆ›å»ºé…ç½®å¯¹è±¡"""
        return cls(**config_dict)

class OptimizationDashboard:
    def __init__(self):
        self.top_params = []
        self.total_tasks = 0
        self.completed = 0
        
    def start_progress(self, total):
        self.total_tasks = total
        self.completed = 0
        print(f"å¼€å§‹å‚æ•°ä¼˜åŒ–ï¼Œæ€»ä»»åŠ¡æ•°: {total}")
        
    def update_progress(self, advance=1):
        self.completed += advance
        print(f"è¿›åº¦: {self.completed}/{self.total_tasks} ({self.completed/self.total_tasks:.1%})")
        
    def print_best_result(self, results):
        # è¿‡æ»¤æ— æ•ˆç»“æœ
        valid_results = [r for r in results if r.get('metrics')]
        
        if valid_results:
            # å§‹ç»ˆæ˜¾ç¤ºå…¨å±€æœ€ä¼˜å¤æ™®ç»„åˆ
            best_sharpe = max(valid_results, 
                            key=lambda x: x['metrics'].get('sharpe_ratio', -np.inf))
            print("\nğŸ“ˆ å½“å‰æœ€ä¼˜å¤æ™®ç»„åˆ:")
            for k, v in best_sharpe['params'].items():
                print(f"  â–¸ {k}: {v}")
            print(f"  å¤æ™®æ¯”ç‡: {best_sharpe['metrics']['sharpe_ratio']:.2f}")
            print(f"  å¹´åŒ–æ”¶ç›Š: {best_sharpe['metrics']['annualized_return']:.2%}")
            print(f"  æœ€å¤§å›æ’¤: {best_sharpe['metrics']['max_drawdown']:.2%}")
            print(f"  æ˜¯å¦åˆæ ¼: {'âœ…' if best_sharpe['qualified'] else 'âŒ'}")

            # æ˜¾ç¤ºå…¨å±€æ”¶ç›Šæœ€é«˜çš„ç»„åˆï¼ˆå³ä½¿ä¸åˆæ ¼ï¼‰
            best_profit = max(valid_results, 
                            key=lambda x: x['metrics'].get('annualized_return', -np.inf))
            print("\nğŸ† å…¨å±€æœ€é«˜æ”¶ç›Šç»„åˆ:")
            for k, v in best_profit['params'].items():
                print(f"  â–¸ {k}: {v}")
            print(f"  å¹´åŒ–æ”¶ç›Š: {best_profit['metrics']['annualized_return']:.2%}")
            print(f"  å¤æ™®æ¯”ç‡: {best_profit['metrics'].get('sharpe_ratio', 0):.2f}")
            print(f"  æœ€å¤§å›æ’¤: {best_profit['metrics']['max_drawdown']:.2%}")
            print(f"  æ˜¯å¦åˆæ ¼: {'âœ…' if best_profit['qualified'] else 'âŒ'}")

class ParameterOptimizer:
    def __init__(self, base_config, param_space, optimization_config=None):
        self.base_config = base_config
        self.param_space = param_space
        self.optimization_config = optimization_config or OptimizationConfig()
        self.dashboard = OptimizationDashboard()

    def _is_qualified(self, metrics):
        """æ£€æŸ¥å‚æ•°ç»„åˆæ˜¯å¦æ»¡è¶³é£æ§è¦æ±‚"""
        return (
            metrics['annualized_return'] >= self.optimization_config.min_annual_return and
            metrics['max_drawdown'] <= self.optimization_config.max_drawdown and
            metrics['sharpe_ratio'] >= self.optimization_config.min_sharpe and
            metrics['win_rate'] >= self.optimization_config.min_win_rate
        )
    
    best_score = -np.inf
    best_params = None
    completed = 0

    # åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°
    def grid_search(self, data, n_jobs=-1, verbose=False):
        """å¹¶è¡ŒåŒ–ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        grid = list(ParameterGrid(self.param_space))
        total_combinations = len(grid)
        self.dashboard.start_progress(total_combinations)
        
        print(f"\nğŸ”§ æ­£åœ¨åˆå§‹åŒ–{total_combinations}ä¸ªå‚æ•°ç»„åˆ...", flush=True)
        print(f"âš™ï¸ å¯åŠ¨{n_jobs if n_jobs != -1 else 'å…¨éƒ¨'}ä¸ªå¹¶è¡Œå·¥ä½œè¿›ç¨‹", flush=True)
        print(f"ğŸ•’ å¼€å§‹æ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}", flush=True)

        # åˆå§‹åŒ–æœ€ä½³ç»“æœè·Ÿè¸ª
        self.best_score = -np.inf
        self.best_params = None

        # åŸå­æ“ä½œè¿›åº¦è·Ÿè¸ª
        from joblib.externals.loky import get_reusable_executor
        
        def process_result(result):
            # ä½¿ç”¨åŸå­æ“ä½œæ›´æ–°è¿›åº¦
            self.completed += 1
            elapsed = pd.Timestamp.now().strftime('%H:%M:%S')
            print(f"[{elapsed}] å·²å®Œæˆ {self.completed}/{total_combinations} ({self.completed/total_combinations:.1%})")
            print(str(result))
            if result and result['metrics']:
                # ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ–¹å¼æ›´æ–°æœ€ä½³ç»“æœ
                current_score = result['metrics']['sharpe_ratio']
                if current_score > self.best_score:
                    self.best_score = current_score
                    self.best_params = result['params'].copy()
                    print(f"\nğŸŒŸ å‘ç°æ–°çš„æœ€ä½³ç»„åˆï¼ˆå¤æ™®æ¯”ç‡:{current_score:.2f}ï¼‰:")
                    for k, v in self.best_params.items():
                        print(f"   â”œ {k}: {v}")
                    print(f"   â”œ å¹´åŒ–æ”¶ç›Š: {result['metrics']['annualized_return']:.2%}")
                    print(f"   â”” æœ€å¤§å›æ’¤: {result['metrics']['max_drawdown']:.2%}")
            return result

        try:
            # å°†æ•°æ®é¢„å¤„ç†ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
            serializable_data = {
                'features': data.values.astype(np.float64).tolist(),
                'index': data.index.tz_localize(None).astype('datetime64[ns]').astype(np.int64).tolist(),
                'columns': data.columns.tolist(),
                'dtypes': {
                    'index': 'datetime64[ns]',
                    'features': 'float64'
                }
            }
            
            # æ·»åŠ å¹¶è¡Œä»»åŠ¡å¯åŠ¨å‰æ£€æŸ¥ç‚¹
            print(f"ğŸ” æ­£åœ¨å¯åŠ¨å¹¶è¡Œä»»åŠ¡ï¼Œé¦–ä¸ªå‚æ•°ç»„åˆç¤ºä¾‹: {grid[0]}", flush=True)
            print(f"ğŸ” æœ€åä¸€ä¸ªå‚æ•°ç»„åˆç¤ºä¾‹: {grid[-1]}", flush=True)
            print(f"ğŸ” åºåˆ—åŒ–æ•°æ®ç±»å‹æ£€æŸ¥: {type(serializable_data)} é•¿åº¦: {len(serializable_data['features'])}", flush=True)
            
            # å¯ç”¨joblibè¯¦ç»†æ—¥å¿—å¹¶æ·»åŠ è¶…æ—¶è®¾ç½®
            # æ˜¾å¼æ”¶é›†ç»“æœå¹¶è§¦å‘å›è°ƒ
            # å…ˆåºåˆ—åŒ–æ•°æ®ï¼ˆé¿å…åœ¨å¹¶è¡Œä»»åŠ¡ä¸­é‡å¤å¤„ç†ï¼‰
            serializable_data = {
                'features': data.values.astype(np.float64).tolist(),
                'index': data.index.tz_localize(None).astype('datetime64[ns]').astype(np.int64).tolist(),
                'columns': data.columns.tolist(),
                'dtypes': {
                    'index': 'datetime64[ns]',
                    'features': 'float64'
                }
            }

            # åˆ›å»ºä»»åŠ¡åŒ…è£…å‡½æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
            def task_wrapper(params):
                result = self._evaluate_params(params, serializable_data, verbose)
                processed_result = process_result(result)
                return processed_result
            print("âœ… å¹¶è¡Œä»»åŠ¡å·²æˆåŠŸå¯åŠ¨", flush=True)
            # æ‰§è¡Œå¹¶è¡Œä»»åŠ¡å¹¶å®æ—¶å¤„ç†ç»“æœ
            with Parallel(n_jobs=n_jobs, verbose=5, timeout=3600) as parallel:
                results = []
                for result in parallel(delayed(task_wrapper)(params) for params in grid):
                    results.append(result)
            
            # è¿‡æ»¤åˆæ ¼ç»“æœ
            qualified_results = [res for res in results if res['qualified']]
            self._save_results(qualified_results)
            
            # æœ€ç»ˆç»“æœå±•ç¤º
            self.dashboard.print_best_result(results)
            
            return sorted(qualified_results, key=lambda x: x['metrics']['sharpe_ratio'], reverse=True)
        finally:
            # æ¸…ç†è¿›åº¦è·Ÿè¸ª
            self.dashboard.total_tasks = 0
            self.dashboard.completed = 0
            
        return sorted(qualified_results, key=lambda x: x['metrics']['sharpe_ratio'], reverse=True)

    def _evaluate_params(self, params, data, verbose=False):
        """æ‰§è¡Œå•ä¸ªå‚æ•°ç»„åˆçš„å›æµ‹è¯„ä¼°ï¼ˆå­è¿›ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼‰"""
        if verbose:
            print(f"\nğŸ” å¼€å§‹å›æµ‹å‚æ•°ç»„åˆ:", flush=True)
            for k,v in params.items():
                print(f"  {k}: {v}", flush=True)
            
        # é‡å»ºDataFrameæ•°æ®ï¼ˆå…¼å®¹åŸå§‹DataFrameå’Œåºåˆ—åŒ–æ•°æ®ï¼‰
        if isinstance(data, pd.DataFrame):
            df = data
        else:
            try:
                df = pd.DataFrame(
                    data['features'],
                    index=pd.to_datetime(data['index']),
                    columns=data['columns']
                )
            except KeyError as e:
                raise ValueError("Invalid data format. Expected serialized data with 'features' and 'index' fields") from e
        if verbose:
            print(f"âœ… æ•°æ®é‡å»ºå®Œæˆï¼Œå…±{len(df)}æ¡è®°å½•")
        
        # åˆ›å»ºå¯åºåˆ—åŒ–çš„é…ç½®å­—å…¸ï¼ˆé¿å…ä¼ é€’å¤æ‚å¯¹è±¡ï¼‰
        config_dict = {
            'data_dir': 'ds_fee/market_data',
            'output_dir': 'output',
            **params
        }
        
        # åˆ›å»ºå¼•æ“å¹¶æ³¨å…¥åŠ¨æ€å‚æ•°
        engine = BacktestEngine(config_dict)
        # æ›´æ–°é…ç½®å‚æ•°å¹¶è®¾ç½®é»˜è®¤æ‰‹ç»­è´¹ç‡
        actual_fee_rate = engine.actual_funding_rate or 0.0002  # é»˜è®¤0.02%
        config_dict.update({
            'backtest': {
                'start_date': engine.actual_start_date,
                'end_date': engine.actual_end_date
            },
            'fee_rate': actual_fee_rate
        })
        # é‡æ–°åˆ›å»ºå¼•æ“ç¡®ä¿å‚æ•°ç”Ÿæ•ˆï¼ˆä½¿ç”¨åˆå¹¶åçš„é…ç½®ï¼‰
        engine = BacktestEngine({
            **config_dict,
            'fee_rate': actual_fee_rate  # æ˜¾å¼ä¼ é€’æœ‰æ•ˆè´¹ç‡
        })
        engine.preprocessed_data = df  # ç›´æ¥æ³¨å…¥é¢„å¤„ç†æ•°æ®
        
        try:
            results = engine.run_backtest(config_dict, verbose=verbose, saveResults=False)
        except Exception as e:
            raise ValueError(f"âš ï¸ å›æµ‹å¤±è´¥: {str(e)}")
        
        # ç¡®ä¿risk_metricså­˜åœ¨  
        if 'risk_metrics' not in results:
            raise ValueError("âš ï¸ å›æµ‹ç»“æœç¼ºå°‘risk_metricså­—æ®µ")
        if verbose:
            print("\nğŸ“Š å›æµ‹ç»“æœè¯¦æƒ…:")
            print(f"âœ… å›æµ‹æˆåŠŸå®Œæˆ")
            print(f"ğŸ“… å›æµ‹æœŸé—´: {config_dict['backtest']['start_date']} è‡³ {config_dict['backtest']['end_date']}")
            print(f"ğŸ’¸ æ‰‹ç»­è´¹ç‡: {config_dict['fee_rate']:.4f}")
            print(f"ğŸ”„ æ€»äº¤æ˜“æ¬¡æ•°: {results['risk_metrics']['total_trades']}")
            print(f"â±ï¸ å¹³å‡æŒä»“å¤©æ•°: {results['risk_metrics'].get('avg_holding_days', 0):.1f}")
            print(f"ğŸ’° å‡€åˆ©æ¶¦: {results['risk_metrics']['net_profit']:.2f}")
            print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {results['risk_metrics']['max_drawdown']:.2%}")
            print(f"ğŸ† å¹´åŒ–æ”¶ç›Šç‡: {results['risk_metrics']['annualized_return']:.2%}")
            print(f"âš–ï¸ å¤æ™®æ¯”ç‡: {results['risk_metrics'].get('sharpe_ratio', 0):.2f}")
        
        # å¤„ç†å¯èƒ½ç¼ºå¤±çš„metricså­—æ®µ
        metrics = results.get('risk_metrics')
        
        return {
            'params': params.copy(),
            'metrics': {
                'annualized_return': metrics.get('annualized_return', -np.inf),
                'max_drawdown': metrics.get('max_drawdown', 1.0),
                'sharpe_ratio': metrics.get('sharpe_ratio', -np.inf),
                'profit_factor': metrics.get('profit_factor', 0),
                'win_rate': metrics.get('win_rate', 0),
                'volatility': metrics.get('annualized_volatility', np.inf),
                'avg_holding_days': metrics.get('avg_holding_days', 0),
                'total_trades': metrics.get('total_trades', 0),
                'net_profit': metrics.get('net_profit', -np.inf)
            },
            'qualified': self._is_qualified(metrics) if metrics else False,
            'error': None
        }

    def _save_results(self, results):
        """ä¿å­˜ä¼˜åŒ–ç»“æœå’Œå†å²è®°å½•"""
        history_dir = "output/optimization_history"
        os.makedirs(history_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{history_dir}/optimized_params_{timestamp}.csv"
        
        # æ„å»ºåŒ…å«å®Œæ•´æŒ‡æ ‡çš„ç»“æœDataFrame
        df = pd.DataFrame([{
            **res['params'],
            'annualized_return': res['metrics']['annualized_return'],
            'max_drawdown': res['metrics']['max_drawdown'],
            'sharpe_ratio': res['metrics']['sharpe_ratio'],
            'win_rate': res['metrics']['win_rate'],
            'volatility': res['metrics']['volatility'],
            'profit_factor': res['metrics']['profit_factor'],
            'avg_holding_days': res['metrics']['avg_holding_days'],
            'total_trades': res['metrics']['total_trades'],
            'qualified': res['qualified']
        } for res in results if res['metrics']])
        
        # ä¿å­˜æœ¬æ¬¡ç»“æœ
        df.to_csv(filename, index=False)
        
        # æ›´æ–°ä¼˜åŒ–æ—¥å¿—
        log_entry = {
            'timestamp': timestamp,
            'total_combinations': len(results),
            'qualified_count': len([r for r in results if r['qualified']]),
            'best_sharpe': df['sharpe_ratio'].max() if not df.empty else None
        }
        log_path = f"{history_dir}/optimization_log.csv"
        pd.DataFrame([log_entry]).to_csv(log_path, mode='a', header=not os.path.exists(log_path))

    def genetic_optimization(self, data, population_size=50, generations=20, verbose=False):
        """é—ä¼ ç®—æ³•ä¼˜åŒ–å™¨"""
        # åˆå§‹åŒ–ç§ç¾¤
        population = self._initialize_population(population_size)
        
        for gen in range(generations):
            # è¯„ä¼°é€‚åº”åº¦
            # è¿‡æ»¤æ— æ•ˆè¯„ä¼°ç»“æœ
            evaluated_pop = [res for res in 
                           (self._evaluate_params(ind, data) for ind in population)
                           if res['metrics'] is not None]
            
            # é€‰æ‹©
            selected = self._selection(evaluated_pop)
            
            # äº¤å‰
            offspring = self._crossover(selected)
            
            # å˜å¼‚
            population = self._mutation(offspring)
            
            # æ˜¾ç¤ºè¿›åº¦
            self.dashboard.print_best_result(evaluated_pop)
        
        return sorted(evaluated_pop, key=lambda x: x['metrics']['sharpe_ratio'], reverse=True)

    def _initialize_population(self, size):
        """ç”Ÿæˆåˆå§‹ç§ç¾¤"""
        population = []
        for _ in range(size):
            individual = {
                'spread_threshold': np.round(np.random.uniform(0.002, 0.006), 4),
                'leverage': np.random.choice([2, 3, 4]),
                'max_hold_seconds': np.random.choice([3600, 7200, 14400]),
                'take_profit': np.round(np.random.uniform(0.004, 0.012), 4),
                'stop_loss': np.round(np.random.uniform(0.003, 0.008), 4)
            }
            population.append(individual)
        return population

    def _selection(self, population):
        """é”¦æ ‡èµ›é€‰æ‹©"""
        selected = []
        tournament_size = 5
        for _ in range(len(population)):
            candidates = np.random.choice(population, tournament_size, replace=False)
            winner = max(
                [c for c in candidates if c['metrics'] is not None], 
                key=lambda x: x['metrics'].get('sharpe_ratio', -np.inf)
            )
            selected.append(winner['params'])
        return selected

    def _crossover(self, parents):
        """å‡åŒ€äº¤å‰"""
        offspring = []
        for i in range(0, len(parents), 2):
            p1 = parents[i]
            p2 = parents[i+1] if i+1 < len(parents) else parents[0]
            child = {}
            for key in p1:
                if np.random.rand() < 0.5:
                    child[key] = p1[key]
                else:
                    child[key] = p2[key]
            offspring.append(child)
        return offspring

    def random_sampling(self, raw_data, samples=500):
        """éšæœºé‡‡æ ·ä¼˜åŒ–"""
        print(f"\nğŸ² å¼€å§‹éšæœºé‡‡æ ·ï¼Œæ ·æœ¬æ•°: {samples}")
        
        # ç»Ÿä¸€æ•°æ®åºåˆ—åŒ–æ ¼å¼
        data = {
            'features': raw_data.values.astype(np.float64).tolist(),
            'index': raw_data.index.tz_localize(None).astype('datetime64[ns]').astype(np.int64).tolist(),
            'columns': raw_data.columns.tolist(),
            'dtypes': {
                'index': 'datetime64[ns]',
                'features': 'float64'
            }
        }
        results = []
        for i in range(samples):
            # ç”Ÿæˆéšæœºå‚æ•°
            params = {
                'spread_threshold': np.round(np.random.uniform(0.002, 0.006), 4),
                'leverage': np.random.choice([2, 3, 4]),
                'max_hold_seconds': np.random.choice([3600, 7200, 14400]),
                'take_profit': np.round(np.random.uniform(0.004, 0.012), 4),
                'stop_loss': np.round(np.random.uniform(0.003, 0.008), 4)
            }
            # è¯„ä¼°å‚æ•°
            result = self._evaluate_params(params, data)
            results.append(result)
            # æ›´æ–°è¿›åº¦
            if (i+1) % 10 == 0 or (i+1) == samples:
                print(f"è¿›åº¦: {i+1}/{samples} ({(i+1)/samples:.1%})")
                self.dashboard.print_best_result(results)
        # è¿‡æ»¤æ— æ•ˆç»“æœå¹¶æ’åº
        valid_results = [r for r in results if r['metrics'] is not None]
        return sorted(valid_results, key=lambda x: x['metrics'].get('sharpe_ratio', -np.inf), reverse=True)

    def _mutation(self, offspring):
        """é«˜æ–¯å˜å¼‚ï¼ˆæ›´æ–°å‚æ•°èŒƒå›´ï¼‰"""
        mutated = []
        for params in offspring:
            mutated_params = params.copy()
            # ä»·å·®é˜ˆå€¼å˜å¼‚ (æ–°èŒƒå›´0.002-0.006)
            if np.random.rand() < 0.1:
                mutated_params['spread_threshold'] = np.clip(
                    np.random.normal(params['spread_threshold'], 0.001),
                    0.002, 0.006
                ).round(4)
            # æ æ†å€æ•°å˜å¼‚ (æ–°èŒƒå›´2-4)
            if np.random.rand() < 0.1:
                mutated_params['leverage'] = np.random.choice([2, 3, 4])
            # æŒä»“æ—¶é—´å˜å¼‚ (æ–°é€‰é¡¹)
            if np.random.rand() < 0.1:
                mutated_params['max_hold_seconds'] = np.random.choice([3600, 7200, 14400])
            # æ­¢ç›ˆå‚æ•°å˜å¼‚ (æ–°èŒƒå›´0.004-0.012)
            if np.random.rand() < 0.1:
                mutated_params['take_profit'] = np.clip(
                    np.random.normal(params['take_profit'], 0.001),
                    0.004, 0.012
                ).round(4)
            # æ­¢æŸå‚æ•°å˜å¼‚ (æ–°èŒƒå›´0.003-0.008)
            if np.random.rand() < 0.1:
                mutated_params['stop_loss'] = np.clip(
                    np.random.normal(params['stop_loss'], 0.001),
                    0.003, 0.008
                ).round(4)
            mutated.append(mutated_params)
        return mutated

    def _sharpe_scorer(self, estimator, X, y):
        """è‡ªå®šä¹‰å¤æ™®æ¯”ç‡è¯„åˆ†å‡½æ•°"""
        estimator.run_backtest()
        metrics = estimator.analyze_performance()
        return metrics['sharpe_ratio']

    def save_full_report(self, results, output_dir):
        """ä¿å­˜å®Œæ•´ä¼˜åŒ–æŠ¥å‘Š"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜CSVç»“æœ
        df = pd.DataFrame([{
            **res['params'],
            **res['metrics'],
            'qualified': res['qualified']
        } for res in results])
        csv_path = f"{output_dir}/optimization_report_{timestamp}.csv"
        df.to_csv(csv_path, index=False)
        
        # ä¿å­˜å…ƒæ•°æ®
        # åªå¤„ç†åˆæ ¼ç»“æœ
        qualified = [res for res in results if res['qualified']]
        meta = {
            "optimization_date": timestamp,
            "total_combinations": len(results),
            "qualified_count": len(qualified),
            "best_sharpe": max((res['metrics']['sharpe_ratio'] for res in qualified), default=None)
        } if qualified else {
            "optimization_date": timestamp,
            "total_combinations": len(results),
            "qualified_count": 0,
            "best_sharpe": None
        }
        json_path = f"{output_dir}/metadata_{timestamp}.json"
        with open(json_path, 'w') as f:
            json.dump(meta, f, indent=2)

if __name__ == "__main__":
    import argparse
    import json
    from .config import load_base_config
    
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='é‡åŒ–ç­–ç•¥å‚æ•°ä¼˜åŒ–æ‰§è¡Œå™¨', 
                                   formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--method', choices=['grid','genetic','random'], default='genetic',
                      help='é€‰æ‹©ä¼˜åŒ–ç®—æ³•: grid-ç½‘æ ¼æœç´¢, genetic-é—ä¼ ç®—æ³•, random-éšæœºé‡‡æ ·')
    parser.add_argument('--output', type=str, default='optimization_results',
                      help='ç»“æœè¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--jobs', type=int, default=-1,
                      help='å¹¶è¡Œä»»åŠ¡æ•°ï¼ˆ-1è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨CPUæ ¸å¿ƒï¼‰')
    parser.add_argument('--verbose', action='store_true',
                      help='å¯ç”¨è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    args = parser.parse_args()

    # åˆå§‹åŒ–ä¼˜åŒ–å™¨é…ç½®
    base_config = load_base_config()
    param_space = {
        'spread_threshold': np.round(np.linspace(0.002, 0.006, 5), 4),    # ä¼˜åŒ–ä»·å·®èŒƒå›´0.2%-0.6%
        'leverage': [2, 3, 4],                     # æ æ†å€æ•°ä¼˜åŒ–é€‰é¡¹
        'max_hold_seconds': [3600, 7200, 14400],   # æŒä»“æ—¶é—´1-4å°æ—¶
        'take_profit': np.round(np.linspace(0.004, 0.012, 4), 4),  # æ­¢ç›ˆ0.4%-1.2%
        'stop_loss': np.round(np.linspace(0.003, 0.008, 4), 4),     # æ­¢æŸ0.3%-0.8%
        'min_funding_rate': np.round(np.linspace(0.0005, 0.002, 4), 4),  # æœ€ä½èµ„é‡‘è´¹ç‡0.05%-0.2%
        'risk_per_trade': [0.01, 0.02, 0.03]  # å•ç¬”äº¤æ˜“é£é™©1%-3%
    }
    optimizer = ParameterOptimizer(base_config, param_space)

    try:
        # ä½¿ç”¨BacktestEngineåŠ è½½é¢„å¤„ç†æ•°æ®
        # é€šè¿‡é…ç½®åˆå§‹åŒ–å¼•æ“
        from .config import load_base_config
        config = load_base_config()
        engine = BacktestEngine(config)
        engine.preprocess_data()
        data = engine.preprocessed_data
        
        print(f"âœ… æˆåŠŸåŠ è½½é¢„å¤„ç†æ•°æ®ï¼ˆ{len(data):,} æ¡è®°å½•ï¼‰")

        # æ‰§è¡Œä¼˜åŒ–
        print(f"ğŸš€ å¼€å§‹å‚æ•°ä¼˜åŒ–ï¼ˆæ–¹æ³•: {args.method.upper()}ï¼‰")
        if args.method == 'grid':
            results = optimizer.grid_search(data, n_jobs=args.jobs, verbose=args.verbose)
        elif args.method == 'genetic':
            results = optimizer.genetic_optimization(data, verbose=args.verbose)
        elif args.method == 'random':
            results = optimizer.random_sampling(data, verbose=args.verbose)
        
        # ä¿å­˜ç»“æœ
        # è¿‡æ»¤æ— æ•ˆç»“æœå¹¶ä¿å­˜
        valid_results = [r for r in results if r['metrics'] is not None]
        optimizer.save_full_report(valid_results, args.output)
        print(f"\nğŸ‰ ä¼˜åŒ–å®Œæˆï¼æœ‰æ•ˆå‚æ•°ç»„åˆ: {len(valid_results)} ä¸ª")
        print(f"ğŸ“‚ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {os.path.abspath(args.output)}")
        
        # å¤„ç†ä¼˜åŒ–ç»“æœ
        if valid_results:
            qualified = [res for res in results if res['qualified']]
            print(f"\nğŸ‰ ä¼˜åŒ–å®Œæˆï¼æ€»å‚æ•°ç»„åˆ: {len(results)} åˆæ ¼å‚æ•°: {len(qualified)}")
            
            if qualified:
                best_result = max(qualified, key=lambda x: x['metrics']['sharpe_ratio'])
                print("\nğŸ† æœ€ä½³å‚æ•°ç»„åˆ:")
                for k, v in best_result['params'].items():
                    print(f"  â–¸ {k:.<20} {v}")
                print(f"â­ å¤æ™®æ¯”ç‡: {best_result['metrics']['sharpe_ratio']:.2f}")
            else:
                print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆé£æ§è¦æ±‚çš„å‚æ•°ç»„åˆï¼Œå»ºè®®ï¼š")
                print("1. æ£€æŸ¥ç­–ç•¥é€»è¾‘æ˜¯å¦æ­£ç¡®")
                print("2. è°ƒæ•´ä¼˜åŒ–å‚æ•°èŒƒå›´")
                print("3. æ”¾å®½é£æ§æŒ‡æ ‡é˜ˆå€¼")
        else:
            print("\nâŒ ä¼˜åŒ–å¤±è´¥ï¼šæœªå¾—åˆ°ä»»ä½•æœ‰æ•ˆç»“æœ")

    except FileNotFoundError as e:
        print(f"âŒ å¸‚åœºæ•°æ®ç›®å½•ä¸å­˜åœ¨: {e.filename}")
        print("è¯·æ£€æŸ¥ds_fee/market_dataç›®å½•ç»“æ„æ˜¯å¦ç¬¦åˆè¦æ±‚")
    except pd.errors.EmptyDataError:
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯: {args.data}")
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤±è´¥: {str(e)}")
        raise
