import numpy as np
import pandas as pd
from abc import ABC, abstractmethod
from datetime import datetime
import os
import json
from ds_fee.backtest.BacktestEngine import BacktestEngine
from .params import OptimizationParams

import argparse

class OptimizationDashboard:
    def print_best_result(self, results):
        # è¿‡æ»¤æ— æ•ˆç»“æœ
        valid_results = [r for r in results if r.get('metrics')]
        
        if valid_results:
            # å§‹ç»ˆæ˜¾ç¤ºå…¨å±€æœ€ä¼˜å¤æ™®ç»„åˆ
            best_sharpe = max(valid_results, 
                            key=lambda x: x['metrics'].get('sharpe_ratio', -np.inf))
            print("\nğŸ“ˆ å½“å‰æœ€ä¼˜å¤æ™®ç»„åˆ:")
            for k, v in best_sharpe['params'].items():
                print(f"  â–¸ {k}: {v}")
            print(f"  å¤æ™®æ¯”ç‡: {best_sharpe['metrics']['sharpe_ratio']:.2f}")
            print(f"  å¹´åŒ–æ”¶ç›Š: {best_sharpe['metrics']['annualized_return']:.2%}")
            print(f"  æœ€å¤§å›æ’¤: {best_sharpe['metrics']['max_drawdown']:.2%}")
            print(f"  æ˜¯å¦åˆæ ¼: {'âœ…' if best_sharpe['qualified'] else 'âŒ'}")

            # æ˜¾ç¤ºå…¨å±€æ”¶ç›Šæœ€é«˜çš„ç»„åˆï¼ˆå³ä½¿ä¸åˆæ ¼ï¼‰
            best_profit = max(valid_results, 
                            key=lambda x: x['metrics'].get('annualized_return', -np.inf))
            print("\nğŸ† å…¨å±€æœ€é«˜æ”¶ç›Šç»„åˆ:")
            for k, v in best_profit['params'].items():
                print(f"  â–¸ {k}: {v}")
            print(f"  å¹´åŒ–æ”¶ç›Š: {best_profit['metrics']['annualized_return']:.2%}")
            print(f"  å¤æ™®æ¯”ç‡: {best_profit['metrics'].get('sharpe_ratio', 0):.2f}")
            print(f"  æœ€å¤§å›æ’¤: {best_profit['metrics']['max_drawdown']:.2%}")
            print(f"  æ˜¯å¦åˆæ ¼: {'âœ…' if best_profit['qualified'] else 'âŒ'}")

def evaluate_params(params, data, base_config, dashboard, verbose=False):
    """æ‰§è¡Œå•ä¸ªå‚æ•°ç»„åˆçš„å›æµ‹è¯„ä¼°"""
    if verbose:
        print(f"\nğŸ” å¼€å§‹å›æµ‹å‚æ•°ç»„åˆ:", flush=True)
        for k,v in params.items():
            print(f"  {k}: {v}", flush=True)
    
    try:
        # åˆå¹¶åŸºç¡€é…ç½®å‚æ•°
        base_config_dict = base_config.to_dict() if hasattr(base_config, 'to_dict') else dict(base_config)
        full_config = {
            **base_config_dict,  # åŸºç¡€é…ç½®å‚æ•°
            **params            # ä¼˜åŒ–å‚æ•°
        }
        
        # åˆå§‹åŒ–å¼•æ“
        engine = BacktestEngine(config=full_config)
        
        # é¢„å¤„ç†æ•°æ®
        engine.data_processor.preprocessed_data = data.copy()
        
        # æ‰§è¡Œå›æµ‹
        results = engine.backtest_core.run_backtest(params, verbose=False)
        metrics = results.get('risk_metrics', {})
        
        # å¢åŠ èµ„é‡‘è´¹æ”¶ç›Šæƒé‡çš„è¯„ä¼°
        funding_ratio = metrics.get('funding_ratio%', 0) / 100  # è½¬æ¢ä¸ºå°æ•°
        funding_weight = 1.2  # èµ„é‡‘è´¹æ”¶ç›Šæƒé‡
        
        # è®¡ç®—åŠ æƒå¤æ™®æ¯”ç‡
        weighted_sharpe = metrics.get('sharpe_ratio', 0) * (1 + funding_ratio * funding_weight)
        
        # æ›´æ–°è¯„ä¼°æŒ‡æ ‡
        result = {
            'params': params.copy(),
            'metrics': {
                'annualized_return': metrics.get('annualized_return', -np.inf),
                'max_drawdown': metrics.get('max_drawdown', 1.0),
                'sharpe_ratio': weighted_sharpe,  # ä½¿ç”¨åŠ æƒå¤æ™®æ¯”ç‡
                'profit_factor': metrics.get('profit_factor', 0),
                'win_rate': metrics.get('win_rate', 0),
                'volatility': metrics.get('annualized_volatility', np.inf),
                'funding_ratio': funding_ratio
            },
            'error': None
        }
        
        # ä»é…ç½®ä¸­è·å–é£æ§å‚æ•°
        risk_params = base_config.get('optimizer', {}).get('risk_params', {})
        min_annual_return = risk_params.get('min_annual_return', 0.03)
        max_drawdown = risk_params.get('max_drawdown', 0.30)
        min_sharpe = risk_params.get('min_sharpe', 0.8)
        min_win_rate = risk_params.get('min_win_rate', 0.30)
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³é£æ§è¦æ±‚
        result['qualified'] = (
            result['metrics']['annualized_return'] >= min_annual_return and
            result['metrics']['max_drawdown'] <= max_drawdown and
            result['metrics']['sharpe_ratio'] >= min_sharpe and
            result['metrics']['win_rate'] >= min_win_rate
        )
        
        return result
            
    except Exception as e:
        import traceback
        error_stack = traceback.format_exc()
        print(f"\nâš ï¸ å‚æ•°è¯„ä¼°å¤±è´¥:")
        print(f"å‚æ•°: {params}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"é”™è¯¯å †æ ˆ:\n{error_stack}")
        return {'params': params, 'error': str(e), 'error_stack': error_stack}

class BaseOptimizer(ABC):
    @staticmethod
    def parse_args():
        parser = argparse.ArgumentParser(description='å‚æ•°ä¼˜åŒ–å™¨')
        parser.add_argument('--optimizer', type=str, choices=['genetic', 'random', 'grid'], default='grid',
                          help='ä¼˜åŒ–æ–¹æ³•: genetic(é—ä¼ ç®—æ³•), random(éšæœºæœç´¢), grid(ç½‘æ ¼æœç´¢)')
        parser.add_argument('--population-size', type=int, default=50, help='é—ä¼ ç®—æ³•ç§ç¾¤å¤§å°')
        parser.add_argument('--generations', type=int, default=20, help='é—ä¼ ç®—æ³•è¿­ä»£æ¬¡æ•°')
        parser.add_argument('--samples', type=int, default=500, help='éšæœºæœç´¢é‡‡æ ·æ•°')
        parser.add_argument('--n-jobs', type=int, default=4, help='ç½‘æ ¼æœç´¢å¹¶è¡Œæ•°')
        parser.add_argument('--verbose', action='store_true', help='æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
        return parser.parse_args()

    def __init__(self, base_config):
        self.base_config = base_config
        self.dashboard = OptimizationDashboard()

    @abstractmethod
    def validate_params(self, params) -> None:
        """éªŒè¯ä¼˜åŒ–å™¨å‚æ•°
        
        Args:
            params: OptimizationParamså®ä¾‹ï¼ŒåŒ…å«ä¼˜åŒ–å™¨å‚æ•°
            
        Raises:
            ValueError: å½“å‚æ•°éªŒè¯å¤±è´¥æ—¶æŠ›å‡º
        """
        pass

    @abstractmethod
    def optimize(self, data, params):
        """ä¼˜åŒ–æ–¹æ³•çš„æŠ½è±¡æ¥å£ï¼Œéœ€è¦è¢«å…·ä½“çš„ä¼˜åŒ–å™¨å®ç°
        
        Args:
            data: é¢„å¤„ç†åçš„æ•°æ®ï¼ŒDataFrameæ ¼å¼
            params: ä¼˜åŒ–å™¨å‚æ•°é…ç½®å®ä¾‹
        
        Returns:
            list: æ’åºåçš„ä¼˜åŒ–ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå­—å…¸æ ¼å¼ï¼š
                {
                    'params': å‚æ•°é…ç½®å­—å…¸,
                    'metrics': è¯„ä¼°æŒ‡æ ‡å­—å…¸,
                    'qualified': æ˜¯å¦æ»¡è¶³é£æ§è¦æ±‚çš„å¸ƒå°”å€¼
                }
        """
        pass

    def save_full_report(self, results, output_dir):
        """ä¿å­˜å®Œæ•´ä¼˜åŒ–æŠ¥å‘Š"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜CSVç»“æœ
        df = pd.DataFrame([{
            **res['params'],
            **res['metrics'],
            'qualified': res['qualified']
        } for res in results])
        csv_path = f"{output_dir}/optimization_report_{timestamp}.csv"
        df.to_csv(csv_path, index=False)
        
        # ä¿å­˜å…ƒæ•°æ®
        # åªå¤„ç†åˆæ ¼ç»“æœ
        qualified = [res for res in results if res['qualified']]
        meta = {
            "optimization_date": timestamp,
            "total_combinations": len(results),
            "qualified_count": len(qualified),
            "best_sharpe": max((res['metrics']['sharpe_ratio'] for res in qualified), default=None)
        } if qualified else {
            "optimization_date": timestamp,
            "total_combinations": len(results),
            "qualified_count": 0,
            "best_sharpe": None
        }
        json_path = f"{output_dir}/metadata_{timestamp}.json"
        with open(json_path, 'w') as f:
            json.dump(meta, f, indent=2)